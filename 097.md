Tame Fuzzy Ram

High

# Attacker Will Inflate Voting Power to Manipulate Consensus

### Summary

The lack of duplicate validator checks will cause an artificial inflation of voting power for the protocol as a malicious validator will repeatedly submit the same proof to reach the consensus threshold with fewer unique validators.

### Root Cause

The root cause of the issue is that the `Secp256k1ProverV1::postBatch` function does not enforce uniqueness constraints on the `validatorProofs` array. The contract assumes that each proof corresponds to a distinct validator but does not verify this assumption. As a result, the same validator proof can be included multiple times, and the contract will repeatedly count the same validator's voting power, allowing an attacker to artificially inflate the total voting power and reach the consensus threshold with fewer unique validators than intended.

https://github.com/sherlock-audit/2024-12-seda-protocol/blob/051b5e88a2f530792913910ebf98c50f431b1e3b/seda-evm-contracts/contracts/provers/Secp256k1ProverV1.sol#L110

### Internal Pre-conditions

1. The contract must be in an unpaused state (`whenNotPaused` modifier).
2. The new batch height must be greater than the last processed batch height (`newBatch.batchHeight > s.lastBatchHeight`).
3. The number of signatures must match the number of validator proofs (`signatures.length == validatorProofs.length`).
4. Each validator proof must be valid against the current validators root (`_verifyValidatorProof`).
5. Each signature must be valid and signed by the corresponding validator (`_verifySignature`).

### External Pre-conditions

1. The attacker must have access to at least one valid validator proof and signature.


### Attack Path

1. **Precondition**: The attacker has access to at least one valid validator proof and signature.
2. **Step 1**: The attacker calls the `postBatch` function, passing the same validator proof and signature `n` times in the `validatorProofs` and `signatures` arrays.
3. **Step 2**: The contract processes each validator proof and signature without detecting duplicates, accumulating the same validator's voting power `n` times.
4. **Step 3**: If the accumulated voting power meets or exceeds the consensus threshold (`CONSENSUS_PERCENTAGE`), the contract accepts the batch, even if the voting power comes from a single validator.

### Impact

- **Consensus Manipulation**: An attacker can artificially inflate the voting power and reach consensus with fewer validators than intended, potentially approving invalid or malicious batches.
- **Loss of Trust**: The integrity of the consensus mechanism is compromised, leading to a loss of trust in the protocol.
- **Financial Loss**: If invalid batches are approved, it could lead to financial losses.

### PoC

In the test setup, `validator[0]` holds 75% of the voting power, while `validator[1]`, `validator[2]`, and `validator[3]` together hold 25%. By submitting proofs for these three validators multiple times (three times each), their combined voting power is artificially inflated to **25 Ã— 3 = 75%**, matching `validator[0]`'s voting power and reaching consensus.

run in  `seda-evm-contracts/test/prover/Secp256k1ProverV1.test.ts`

```js
    it('should accept duplicate validator', async () => {
      const { prover, wallets, data } = await loadFixture(deployProverFixture);

      const { newBatchId, newBatch } = generateNewBatchWithId(data.initialBatch);
      const signatures = [await wallets[1].signingKey.sign(newBatchId).serialized, await wallets[2].signingKey.sign(newBatchId).serialized, 
      await wallets[3].signingKey.sign(newBatchId).serialized, await wallets[1].signingKey.sign(newBatchId).serialized, 
      await wallets[2].signingKey.sign(newBatchId).serialized, await wallets[3].signingKey.sign(newBatchId).serialized, 
      await wallets[1].signingKey.sign(newBatchId).serialized, await wallets[2].signingKey.sign(newBatchId).serialized, 
      await wallets[3].signingKey.sign(newBatchId).serialized];
      const [batchSender] = await ethers.getSigners();
      await expect(prover.connect(batchSender).postBatch(newBatch, signatures, [data.validatorProofs[1], data.validatorProofs[2], data.validatorProofs[3], 
        data.validatorProofs[1], data.validatorProofs[2], data.validatorProofs[3],
        data.validatorProofs[1], data.validatorProofs[2], data.validatorProofs[3]]))
        .to.emit(prover, 'BatchPosted')
        .withArgs(newBatch.batchHeight, newBatchId, batchSender.address);
      const lastBatchHeight = await prover.getLastBatchHeight();
      expect(lastBatchHeight).to.equal(newBatch.batchHeight);
    });


```

### Mitigation

To mitigate this vulnerability, the contract should **detect and prevent duplicate validators** in the `validatorProofs` array. This can be achieved by tracking seen validators using a mapping or set and reverting the transaction if a duplicate is encountered.