Gorgeous Shadow Locust

High

# Incorrect Consensus Threshold




## Summary
The contract that verify data batches use an incorrect math check to confirm validator approvals. Instead of requiring signatures from 2/3 of current validators as it demand a fixed number of votes (66,666,666) that only work if the total validator power never changes. This breaks the protocol security when validator numbers grow or shrink.


https://github.com/sherlock-audit/2024-12-seda-protocol/blob/main/seda-evm-contracts/contracts/provers/Secp256k1ProverV1.sol#L25

https://github.com/sherlock-audit/2024-12-seda-protocol/blob/main/seda-evm-contracts/contracts/provers/Secp256k1ProverV1.sol#L122-L125


## Vulnerability detail
The protocol incorrectly assumes 66,666,666 represents 2/3 of total validator power but in reality:
Fixed Threshold assume that
The value 66,666,666 only equals 66.67% when total voting power = 100,000,000
(66,666,666 ÷ 100,000,000 = 0.66666666)


but it create dangerous inconsistencies in consensus approval. When total validator power is 90 million, the protocol as usual will incorrectly demands 66.67 million votes which is 74% of total instead of the required 60 million as being assumed to be 66.67%). then with 150 million total power. it accept 66.67 million votes which is just 44% fundamentally breaking the 2/3 majority security promise.


## Proof of Concept 
**Scenerio 1:**
Imagine three validators with each holding 50 million voting power rsulting to the total as 150 million. then if two validators collude, they control 100 million votes. The protocol mistakenly checks if they exceed 66.67 million as it is a fixed number rather than requiring two-thirds of the actual total power which would be 100 million in this case.


**Scenerio 2:**
In a network with four validators of each holding 25M voting power total 100M then two colluding validators 50M combined attempt to approve a batch. The protocol rejects their attempt because 50M < 66.67M as a fixed threshold which accidentally align with the correct outcome 50% < 66.67%.

**Scenerio 3:**
then another network scenario with 100 validators of each holding 1M voting power (100M total) the  if 34 validators collude as of (34M power) but the protocol incorrectly use a fixed threshold of 66.67M to reject their batch because  (34% < 66.67%) as the threshold isn’t dynamically calculated as 2/3 of the actual total power. This create a false sense of security because the check only work when total power happens to align with the fixed threshold. If the total validator power change of if it increase to 200M, the same flaw logic allow the batches to be approved with just 33% of the real voting power fundamentally breaking the protocol security guarantees.


## **Mathematical proof**

## **Case 1:**
 **Total Voting Power < 100M Parameters**

Total Voting Power = 90M

Correct Threshold :
 2/3 × 90M = 60M


Code Fixed Threshold = 66.67M

Attack Scenario :
Validators accumulate =60M
(66.67% of 90M).

Code Check confirmation that:
60M < 66.67M is rejected 

But in reality
90M/60M =66.67% (so it is supposed to be approved)

output:
then valid batches are wrongfully rejected stoping protocol operations.


## **Case 2:**
 **Total Voting Power > 100M Parameters**

Total Voting Power = 150M

Correct Threshold :
2/3 × 150M = 100M


Code Fixed Threshold = 66.67M

Attack Scenario
Validators accumulate = 70M
(46.67% of 150M).

Code Check confirmation :
70M ≥ 66.67M is approved 

But in reality:
70M/150M = 46.67% < 66.67 % (supposed to be rejected)

output:
so invalid batches gain approval compromising data integrity.



## **Case 3:**
**Total Voting Power = 100M Parameters**

Total Voting Power  = 100M

Correct Threshold = 2/3 × 100M
 = 66.67M


Code Fixed Threshold = 66.67M


Scenario :
Validators accumulate = 66.67M


Code check that :
66.67M ≥ 66.67 (as it is now approved)

And in reality:
66.67M / 100M = 66.67% 

so the code only work as intended when total voting power is just 100M.


## Impact 
it result to false Batch Approvals as batches can be approved with less than 2/3 validator consensus for example with total validator power = 150M, attackers need only 66.67M (44%) to approve batches

Oracle data can be manipulated as the malicious actors can feed incorrect price data to DeFi protocols approve fraudulent cross-chain transactions and censor valid results


## Recommendation 
Calculate required power per batch using actual total validator power
```solidity
struct Batch {
    ......
    uint64 totalVotingPower; // Add this field
}


function postBatch(......) external {
    .......
    uint256 requiredPower = (newBatch.totalVotingPower * 2) / 3;
    
    if (votingPower < requiredPower) {
        revert ConsensusNotReached();
    }
}
```

And  add validation check to ensure that the totalvotingpower match the validator sets
